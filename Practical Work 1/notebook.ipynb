{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.0-final"
    },
    "colab": {
      "name": "notebook.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VtMk6oKXNHGE"
      },
      "source": [
        "# Trabalho Prático 1 - Aplicação de redes neuronais a um novo dataset\n",
        "Objetivo: Explorar o uso de redes neuronais (keras) e comparação dos resultados com o uso de [AutoKeras](https://autokeras.com/).\n",
        "\n",
        "Tipo de tarefa machine learning: Classificação Binária.\n",
        "\n",
        "Dataset utilizado: [Titanic](https://public.opendatasoft.com/explore/dataset/titanic-passengers)\n",
        "\n",
        "Repositório: [GitHub](https://github.com/spamz23/Applied-Deep-Learning/tree/005e14f8c27e176ac310183a5a2216c8838f2abc/Practical%20Work%201)\n",
        "\n",
        "Trabalho realizado por:\n",
        "* [Diogo Silva](https://github.com/spamz23)\n",
        "* [Bruno Silva](https://github.com/brunosilva5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ir64lObGN1-2"
      },
      "source": [
        "# Instalar dependências"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K_n9v8SVNPXZ"
      },
      "source": [
        "!pip install -r requirements.txt\n",
        "# Limpar output\n",
        "from IPython.display import clear_output\n",
        "clear_output()"
      ],
      "execution_count": 402,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-VIqJzxKyC19"
      },
      "source": [
        "# Resultados Reproduzíveis\n",
        "Para uma comparação justa entre os resultados de 2 técnicas diferentes, é importante que os resultados de ambas as técnicas sejam **reproduzíveis**. Para isto podemos fazer \"seed\" nos geradores de números aleatórios usados no backend da biblioteca `keras`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T4qpVl8oxf7O"
      },
      "source": [
        "global_seed = 0 # pode ser qualquer número\n",
        "from numpy.random import seed\n",
        "seed(global_seed)\n",
        "import tensorflow as tf\n",
        "tf.random.set_seed(global_seed)"
      ],
      "execution_count": 403,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "39Dm-ILMNHGF"
      },
      "source": [
        "## 1. Fazer load dos dados\n",
        "Para fazer load e tratar os dados, será utilizada a biblioteca pandas."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jJJP3eHENHGH"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "index = \"PassengerId\"\n",
        "dataset = pd.read_excel(\"titanic-passengers.xlsx\", index_col=\"PassengerId\")\n"
      ],
      "execution_count": 404,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HXkVU-onNHGL"
      },
      "source": [
        "### Primeiro é importante analisar e perceber a estrutura dos dados"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nfI9sHo9NHGM",
        "outputId": "c26b7d55-1976-406b-e06b-1bfb3e683c4b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 420
        }
      },
      "source": [
        "dataset"
      ],
      "execution_count": 405,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Survived</th>\n",
              "      <th>Pclass</th>\n",
              "      <th>Name</th>\n",
              "      <th>Sex</th>\n",
              "      <th>Age</th>\n",
              "      <th>SibSp</th>\n",
              "      <th>Parch</th>\n",
              "      <th>Ticket</th>\n",
              "      <th>Fare</th>\n",
              "      <th>Cabin</th>\n",
              "      <th>Embarked</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>PassengerId</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>431</th>\n",
              "      <td>Yes</td>\n",
              "      <td>1</td>\n",
              "      <td>Bjornstrom-Steffansson, Mr. Mauritz Hakan</td>\n",
              "      <td>male</td>\n",
              "      <td>28.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>110564</td>\n",
              "      <td>26.5500</td>\n",
              "      <td>C52</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>664</th>\n",
              "      <td>No</td>\n",
              "      <td>3</td>\n",
              "      <td>Coleff, Mr. Peju</td>\n",
              "      <td>male</td>\n",
              "      <td>36.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>349210</td>\n",
              "      <td>7.4958</td>\n",
              "      <td>NaN</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>44</th>\n",
              "      <td>Yes</td>\n",
              "      <td>2</td>\n",
              "      <td>Laroche, Miss. Simonne Marie Anne Andree</td>\n",
              "      <td>female</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>SC/Paris 2123</td>\n",
              "      <td>41.5792</td>\n",
              "      <td>NaN</td>\n",
              "      <td>C</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>347</th>\n",
              "      <td>Yes</td>\n",
              "      <td>2</td>\n",
              "      <td>Smith, Miss. Marion Elsie</td>\n",
              "      <td>female</td>\n",
              "      <td>40.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>31418</td>\n",
              "      <td>13.0000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>891</th>\n",
              "      <td>No</td>\n",
              "      <td>3</td>\n",
              "      <td>Dooley, Mr. Patrick</td>\n",
              "      <td>male</td>\n",
              "      <td>32.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>370376</td>\n",
              "      <td>7.7500</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Q</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>779</th>\n",
              "      <td>No</td>\n",
              "      <td>3</td>\n",
              "      <td>Kilgannon, Mr. Thomas J</td>\n",
              "      <td>male</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>36865</td>\n",
              "      <td>7.7375</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Q</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>435</th>\n",
              "      <td>No</td>\n",
              "      <td>1</td>\n",
              "      <td>Silvey, Mr. William Baird</td>\n",
              "      <td>male</td>\n",
              "      <td>50.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>13507</td>\n",
              "      <td>55.9000</td>\n",
              "      <td>E44</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>342</th>\n",
              "      <td>Yes</td>\n",
              "      <td>1</td>\n",
              "      <td>Fortune, Miss. Alice Elizabeth</td>\n",
              "      <td>female</td>\n",
              "      <td>24.0</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>19950</td>\n",
              "      <td>263.0000</td>\n",
              "      <td>C23 C25 C27</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>633</th>\n",
              "      <td>Yes</td>\n",
              "      <td>1</td>\n",
              "      <td>Stahelin-Maeglin, Dr. Max</td>\n",
              "      <td>male</td>\n",
              "      <td>32.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>13214</td>\n",
              "      <td>30.5000</td>\n",
              "      <td>B50</td>\n",
              "      <td>C</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>111</th>\n",
              "      <td>No</td>\n",
              "      <td>1</td>\n",
              "      <td>Porter, Mr. Walter Chamberlain</td>\n",
              "      <td>male</td>\n",
              "      <td>47.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>110465</td>\n",
              "      <td>52.0000</td>\n",
              "      <td>C110</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>891 rows × 11 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "            Survived  Pclass  ...        Cabin Embarked\n",
              "PassengerId                   ...                      \n",
              "431              Yes       1  ...          C52        S\n",
              "664               No       3  ...          NaN        S\n",
              "44               Yes       2  ...          NaN        C\n",
              "347              Yes       2  ...          NaN        S\n",
              "891               No       3  ...          NaN        Q\n",
              "...              ...     ...  ...          ...      ...\n",
              "779               No       3  ...          NaN        Q\n",
              "435               No       1  ...          E44        S\n",
              "342              Yes       1  ...  C23 C25 C27        S\n",
              "633              Yes       1  ...          B50        C\n",
              "111               No       1  ...         C110        S\n",
              "\n",
              "[891 rows x 11 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 405
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VLRDMIQgNHGS"
      },
      "source": [
        "### Informações obtidas\n",
        "Na tabela acima podemos observar que o dataset de treino é composto por 891 linhas (cada linha corresponde a uma pessoa), e por 11 colunas.\n",
        "Podemos então tirar as seguintes conclusões:\n",
        "1. Existem várias colunas com variáveis categóricas (`Name`, `Sex`, `Ticket`, `Cabin`, `Embarked`). Todas estas terão que ser convertidas para números para se poderem usar na rede neuronal.\n",
        "2. Existem algumas colunas com valores `NaN`, ou seja valores em falta. Todas estas também terão que se preencher, ou então remover do dataset.\n",
        "3. A coluna `Survived`, tem apenas valores binários (`0` e `1`). Esta indica se a pessoa em questão sobreviveu (`1`) ou não (`0`). O objetivo da rede neuronal será prever os valores desta coluna. Esta coluna terá que ser separada das restantes, para que seja utilizada como output.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u-WdLyF7NHGZ"
      },
      "source": [
        "# 2. Tratamento dos dados\n",
        "Tal como referido anteriormente existem \"problemas\" nos dados, que terão de ser resolvidos antes de os aplicar numa rede neuronal."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-EduZHjpTek3"
      },
      "source": [
        "## 2.1 Valores em falta"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bvJ6XFfRcaMI"
      },
      "source": [
        "Para saber quais as colunas que contêm valores `NaN` podemos utilizar o seguinte código:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7R0qSnmHcmYL",
        "outputId": "be0c6e65-c6bc-4a35-ea49-e77ebc56995f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(f\"Colunas com valores 'NaN': {dataset.columns[dataset.isna().any()].tolist()}\")"
      ],
      "execution_count": 406,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Colunas com valores 'NaN': ['Age', 'Cabin', 'Embarked']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9s3PhEHANHGZ"
      },
      "source": [
        "Podemos observar que existem 3 colunas com valores `NaN`: `Age`, `Cabin` e `Embarked`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8qHSeQCsTo3h"
      },
      "source": [
        "### 2.1.1 Coluna 'Cabin'"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hDUoHRhERMtw",
        "outputId": "0013e305-1c94-4979-c5dc-e2398a513e97",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "missing = dataset[\"Cabin\"].isnull().sum(axis=0)\n",
        "total = dataset.shape[0]\n",
        "\n",
        "print(f\"Percentagem de valores em falta na coluna 'Cabin': {(missing*100)/total:.2f} %\")"
      ],
      "execution_count": 407,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Percentagem de valores em falta na coluna 'Cabin': 77.10 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YNsOadEPSWjc"
      },
      "source": [
        "Como 77.10 % dos dados, na coluna `Cabin`, estão em falta, iremos proceder à remoção desta coluna, pois a sua inclusão provavelmente não se iria traduzir num ganho de informação na rede neuronal."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EaunDxtwNHGa"
      },
      "source": [
        "dataset.drop(columns=['Cabin'], inplace=True)"
      ],
      "execution_count": 408,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JhcLfAWaTsnW"
      },
      "source": [
        "### 2.1.2 Coluna 'Embarked'"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k869BwlrNHGp",
        "outputId": "fd0b2c65-613d-4d23-ffd5-b174550bcfe0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "missing = dataset[\"Embarked\"].isnull().sum(axis=0)\n",
        "total = dataset.shape[0]\n",
        "\n",
        "print(f\"Percentagem de valores em falta na coluna 'Embarked': {(missing*100)/total:.2f} %\")"
      ],
      "execution_count": 409,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Percentagem de valores em falta na coluna 'Embarked': 0.22 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pJOXYZWgUJy5"
      },
      "source": [
        "Como nesta coluna apenas estão em falta apenas 0.22 % dos dados (o que corresponde a 2 linhas) e trata-se de uma variável categórica, iremos preencher os valores em falta com o valor mais frequente nesta coluna. Para isto iremos utilizar o módulo [SimpleImputer](https://scikit-learn.org/stable/modules/generated/sklearn.impute.SimpleImputer.html#sklearn.impute.SimpleImputer) disponibilizado pela biblioteca [scikit-learn](https://scikit-learn.org/)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BYgh4AWnU26p"
      },
      "source": [
        "from sklearn.impute import SimpleImputer\n",
        "import numpy as np\n",
        "# Criar objeto imputer com estratégia 'most_frequent'\n",
        "imp_most_frequent = SimpleImputer(missing_values=np.nan, strategy='most_frequent', verbose=0)\n",
        "# Aplicar na coluna 'Embarked'. Como vamos aplicar apenas a uma coluna, e o método espera um array 2D, é necessário fazer um reshape dos dados\n",
        "dataset[\"Embarked\"] = imp_most_frequent.fit_transform(dataset[\"Embarked\"].values.reshape(-1, 1))"
      ],
      "execution_count": 410,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IZaLvf47YVg5"
      },
      "source": [
        "### 2.1.3 Coluna 'Age'"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-MGEP4HQYkKH",
        "outputId": "9ffeb621-1e97-4a42-8e81-b1c2cd23c897",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "missing = dataset[\"Age\"].isnull().sum(axis=0)\n",
        "total = dataset.shape[0]\n",
        "\n",
        "print(f\"Percentagem de valores em falta na coluna 'Age': {(missing*100)/total:.2f} %\")"
      ],
      "execution_count": 411,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Percentagem de valores em falta na coluna 'Age': 19.87 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RtrpVE_0YrS9"
      },
      "source": [
        "Nesta coluna estão em falta 19.87 % e trata-se de uma variável numérica, iremos preencher os valores em falta com o valor médio da coluna `Age`. Para isto iremos utilizar o mesmo módulo utilizado na coluna anterior. Existem 2 metodologias possíveis para o preenchimento de variáveis numéricas:\n",
        "1. Utilizar a média dos valores da coluna;\n",
        "2. Utilizar a mediana dos valores da coluna.\n",
        "Para decidir qual a melhor estratégia é necessário observar a curva de distribuição dos dados desta coluna (`Age`)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9y0RE2xuak9z",
        "outputId": "d6b3bd17-739e-4b17-cf8f-3b67bc47be3e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        }
      },
      "source": [
        "dataset[\"Age\"].plot.kde()"
      ],
      "execution_count": 412,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f7977db4080>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 412
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aQv1FsJibHBc"
      },
      "source": [
        "Como é possível observar na figura acima, os dados não seguem uma distribuição normal. Assim concluímos que será mais vantajoso utilizar a mediana para o preenchimento dos valores em falta."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ixsI8oXNbcRc"
      },
      "source": [
        "from sklearn.impute import SimpleImputer\n",
        "import numpy as np\n",
        "# Criar objeto imputer com estratégia 'median'\n",
        "imp_median = SimpleImputer(missing_values=np.nan, strategy='median', verbose=0)\n",
        "# Aplicar na coluna 'Age'. Como vamos aplicar apenas a uma coluna, e o método espera um array 2D, é necessário fazer um reshape dos dados\n",
        "dataset[\"Age\"] = imp_median.fit_transform(dataset[\"Age\"].values.reshape(-1, 1))"
      ],
      "execution_count": 413,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ll4HNbYkcDh9"
      },
      "source": [
        "## 2.2 Transformar valores categóricos em valores numéricos"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4JsL9pdTcMwG"
      },
      "source": [
        "Para saber quais as colunas que contêm valores não numéricos podemos utilizar o seguinte código:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8txtWZfic-uD",
        "outputId": "d03869cc-7f3e-4fc4-9ab0-5dd3d31f8311",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "non_numeric_columns = dataset.columns.difference(dataset._get_numeric_data().columns).to_list()\n",
        "print(f\"Colunas não númericas: {non_numeric_columns}\")"
      ],
      "execution_count": 414,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Colunas não númericas: ['Embarked', 'Name', 'Sex', 'Survived', 'Ticket']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n8Gi28npd2Nm"
      },
      "source": [
        "### 2.2.1 Coluna 'Embarked', 'Sex', 'Name', 'Ticket'\n",
        "Em primeiro lugar iremos remover as colunas `Name` e `Ticket`, pois estas são únicas dos passageiros.\n",
        "Para transformar os valores das restantes colunas (`Embarked`, `Sex`) em valores numéricos iremos utilizar o método `get_dummies()` da biblioteca `pandas`. Este método irá criar, para cada coluna, novas `n` colunas, onde `n` é o numero de diferentes classes presentes em cada coluna. Estas novas colunas irão conter valores binários que indicam se uma linha pertence ou não a essa classe. \n",
        "\n",
        "Uma outra alternativa mais simples seria transformar, para cada coluna, cada classe diferente num valor inteiro diferente. Apesar de ser mais simples, esta tranformação poderia introduzir uma falsa sensação de hierarquiedade nos dados, o que poderia levar a rede neuronal a aprender falsas suposições. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gvWXyxbShK8b"
      },
      "source": [
        "dataset.drop(columns=[\"Name\", \"Ticket\"], inplace=True)\n",
        "# Fazer OneHotEncoding para todas as colunas não numéricas, excepto a coluna 'Survived'\n",
        "dataset = pd.get_dummies(dataset, columns=[\"Embarked\", \"Sex\"])"
      ],
      "execution_count": 415,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6n96-_z-SOvI"
      },
      "source": [
        "### 2.2.2 Coluna 'Survived'\n",
        "As transformações a esta coluna são simples. Esta apenas contêm os valores `Yes` ou `No`. Apenas temos que transformar estes valores para `1` ou `0`, respetivamente."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pBaxkQ7fSx9f"
      },
      "source": [
        "dataset[\"Survived\"] = dataset['Survived'].map({'Yes': 1, 'No': 0})"
      ],
      "execution_count": 416,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e5vLD52VS6pS"
      },
      "source": [
        "## 2.3 Criar novos 'features' a partir de existentes\n",
        "No dataset existe a coluna `SibSp` que indica o número de irmãos/cônjuges, do passageiro, a bordo. Existe também a coluna `Parch` que indica o número de pais/filhos, do passageiro, a bordo.\n",
        "Como estas 2 colunas estão intrinsecamente relacionadas, decidimos uni-las numa só coluna, a que chamamos de `Family_Members`, que indica o número total de familiares a bordo do navio."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xzV6pHzVUInl"
      },
      "source": [
        "# União das colunas\n",
        "dataset[\"Family_Members\"] = dataset[\"SibSp\"] + dataset[\"Parch\"]\n",
        "# Apagar colunas que já não são necessárias\n",
        "dataset.drop(columns=[\"SibSp\", \"Parch\"], inplace=True)"
      ],
      "execution_count": 417,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2urssVSjVwz4"
      },
      "source": [
        "## 2.4 Separação da coluna 'Survived'\n",
        "É também importante separar a coluna `Survived` do resto do dataset. Iremos criar 2 variáveis,  `X`  (irá conter os dados), e `y` (irá conter a coluna `Survived`)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IY6MQEkkY-6c"
      },
      "source": [
        "X = dataset[dataset.columns.difference([\"Survived\"])]\n",
        "y = dataset[[\"Survived\"]]"
      ],
      "execution_count": 418,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "77LhuUhvUlwK"
      },
      "source": [
        "## 2.5 Normalização de dados\n",
        "Para que o modelo tenha uma maior performance, por vezes, é fundamental fazer a normalização dos dados. \n",
        "O objetivo da normalização é alterar os valores das colunas numéricas no conjunto de dados para uma escala comum, sem distorcer as diferenças no intervalos de valores.\n",
        "Neste dataset, como existe uma diferença significativa na escala dos valores, como por exemplo, na coluna `Pclass`, onde os valores variam entre 1 e 3, e as colunas `Age` e `Fare` que variam de `0` a `80` e `0` a `512`, respetivamente, é fundamental normalizar os dados pois os intervalos são muito diferentes."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SMAsivYlUzXE"
      },
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Definir colunas a normalizar\n",
        "cols = [\"Pclass\", \"Age\", \"Family_Members\", \"Fare\"]\n",
        "# Normalizar os dados\n",
        "scaled_columns = StandardScaler().fit_transform(X[cols].values)\n",
        "# Juntar os dados normalizados com os outros\n",
        "X = np.concatenate([X[X.columns.difference(cols)], scaled_columns], axis=1)\n"
      ],
      "execution_count": 419,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9T3r7hkhcU-B"
      },
      "source": [
        "## 2.6 Divisão dos dados\n",
        "\n",
        "É fundamental fazer a divisão do dataset em dados de treino e dados de teste, de modo a poder avaliar a verdadeira capacidade de generalização, esta deve conseguir prever corretamente dados que nunca tenha visto.\n",
        "Uma metodologia bastante comum, é usar 80% dos dados para treinar o modelo e os restantes para avaliar a sua qualidade."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zH3aiLe0YiLZ"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "# Dividir dados em treino e teste. \n",
        "# 20% dos dados são usados para teste\n",
        "# random_state = 42, para resultados reproduzíveis\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state = global_seed, stratify=y)"
      ],
      "execution_count": 420,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gvOs8ZyydOP1"
      },
      "source": [
        "# 3. Construir e treinar as Redes Neuronais"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qSw9-vFqhL4d"
      },
      "source": [
        "# Método para apresentar diferentes métricas de avaliação dos modelos\n",
        "def print_test_results(y_test, y_predict_proba):\n",
        "    # Gerar previsões de classes\n",
        "    y_predict = (y_predict_proba > 0.5).astype(np.int32)\n",
        "    # Comparar previsões com valores reais\n",
        "    print(\"Métricas obtidas nos dados de teste:\")\n",
        "    print(f\"ROC Auc: {sk_metrics.roc_auc_score(y_test, y_predict_proba):.2f}\")\n",
        "    print(f\"Accuracy: {sk_metrics.accuracy_score(y_test, y_predict):.2f}\")\n",
        "    print(f\"F1 Score: {sk_metrics.f1_score(y_test, y_predict):.2f}\")\n",
        "    print(f\"Precision: {sk_metrics.precision_score(y_test, y_predict):.2f}\")"
      ],
      "execution_count": 421,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p2ffRCaJYB2h"
      },
      "source": [
        "## 3.1 Construção manual de rede neuronal Keras"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RpHBT9YTdWaq",
        "outputId": "38a8dadc-3bdc-45bc-af93-fa9a2e9f779d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from keras.callbacks import EarlyStopping\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras import metrics\n",
        "from sklearn import metrics as sk_metrics\n",
        "\n",
        "\n",
        "# Criar modelo sequencial\n",
        "classic_model = Sequential()\n",
        "# Criar camadas 'Dense'\n",
        "classic_model.add(Dense(8, input_dim = X_train.shape[1], activation = 'relu'))\n",
        "classic_model.add(Dense(8, activation = 'relu'))\n",
        "# Ativação = 'sigmoid' para os valores de saída serem 0 ou 1\n",
        "classic_model.add(Dense(1, activation = 'sigmoid'))\n",
        "# Compilar modelo\n",
        "# Optimizar métrica 'AUC' para melhores resultados em classificação binária \n",
        "classic_model.compile(loss = 'binary_crossentropy', optimizer = 'adam')\n",
        "# Treinar modelo\n",
        "classic_model.fit(X_train, y_train, epochs = 120, verbose=0)\n",
        "# Fazer previsões de probabilidades\n",
        "y_predict_proba = classic_model.predict(X_test)\n",
        "# Apresentar resultados\n",
        "print_test_results(y_test, y_predict_proba)\n",
        "\n"
      ],
      "execution_count": 422,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Métricas obtidas nos dados de teste:\n",
            "ROC Auc: 0.86\n",
            "Accuracy: 0.82\n",
            "F1 Score: 0.74\n",
            "Precision: 0.81\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tNJBU6PfzcV5"
      },
      "source": [
        "## 3.2 Uso do `AutoKeras`\n",
        "A biblioteca `AutoKeras` é uma biblioteca de AutoML (*Automated Machine Learning*), e pretende tornar o uso de *machine learning* acessível a todos. \n",
        "\n",
        "O seu objetivo é abstrair um utilizador da escolha dos vários hyper-parâmetros de uma rede neuronal, bem como da sua arquitetura. Esta biblioteca experimenta `n` redes com configurações diferentes, e escolhe automaticamente a que melhor se adapta aos dados, ou seja a que tiver melhor capacidade de generalização."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qJYSzrql0Ym1",
        "outputId": "ecf6009d-0077-4b07-dcf9-49a4e47e52cc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import autokeras as ak\n",
        "\n",
        "# Construir modelo\n",
        "auto_model = ak.StructuredDataClassifier(\n",
        "    overwrite=True,\n",
        "    seed=global_seed,\n",
        "    max_trials=20) # Experimenta 20 modelos diferentes\n",
        "\n",
        "# Prepapar dados\n",
        "X_train = X_train.astype('float32')\n",
        "y_train = y_train.astype('float32')\n",
        "X_test = X_test.astype('float32')\n",
        "y_test = y_test.astype('float32')\n",
        "# Treinar modelo\n",
        "auto_model.fit(X_train, y_train, epochs=120)\n",
        "# Exportar modelo AutoKeras para modelo Keras\n",
        "auto_model = auto_model.export_model()\n",
        "\n",
        "# Prever probabilidades\n",
        "y_predict_proba = auto_model.predict(X_test)\n",
        "# Apresentar resultados\n",
        "print_test_results(y_test, y_predict_proba)\n",
        "\n"
      ],
      "execution_count": 423,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Trial 20 Complete [00h 00m 08s]\n",
            "val_accuracy: 0.7884615659713745\n",
            "\n",
            "Best val_accuracy So Far: 0.8365384340286255\n",
            "Total elapsed time: 00h 02m 17s\n",
            "INFO:tensorflow:Oracle triggered exit\n",
            "Epoch 1/120\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.6878 - accuracy: 0.5941\n",
            "Epoch 2/120\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.5999 - accuracy: 0.7121\n",
            "Epoch 3/120\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.5734 - accuracy: 0.7402\n",
            "Epoch 4/120\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.5416 - accuracy: 0.7654\n",
            "Epoch 5/120\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.5145 - accuracy: 0.7893\n",
            "Epoch 6/120\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.5171 - accuracy: 0.7823\n",
            "Epoch 7/120\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.5096 - accuracy: 0.7907\n",
            "Epoch 8/120\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4959 - accuracy: 0.7879\n",
            "Epoch 9/120\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4831 - accuracy: 0.7978\n",
            "Epoch 10/120\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.4879 - accuracy: 0.7935\n",
            "Epoch 11/120\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4637 - accuracy: 0.8020\n",
            "Epoch 12/120\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4706 - accuracy: 0.7893\n",
            "Epoch 13/120\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4633 - accuracy: 0.7879\n",
            "Epoch 14/120\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4652 - accuracy: 0.7963\n",
            "Epoch 15/120\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4580 - accuracy: 0.7879\n",
            "Epoch 16/120\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4437 - accuracy: 0.7978\n",
            "Epoch 17/120\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.4579 - accuracy: 0.8034\n",
            "Epoch 18/120\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4629 - accuracy: 0.7949\n",
            "Epoch 19/120\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4423 - accuracy: 0.8076\n",
            "Epoch 20/120\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4502 - accuracy: 0.8062\n",
            "Epoch 21/120\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.4566 - accuracy: 0.8104\n",
            "Epoch 22/120\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4311 - accuracy: 0.8090\n",
            "Epoch 23/120\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4427 - accuracy: 0.8076\n",
            "Epoch 24/120\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4448 - accuracy: 0.8006\n",
            "Epoch 25/120\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4406 - accuracy: 0.8034\n",
            "Epoch 26/120\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4390 - accuracy: 0.8062\n",
            "Epoch 27/120\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4478 - accuracy: 0.8076\n",
            "Epoch 28/120\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4248 - accuracy: 0.8048\n",
            "Epoch 29/120\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4181 - accuracy: 0.8174\n",
            "Epoch 30/120\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4261 - accuracy: 0.8216\n",
            "Epoch 31/120\n",
            "23/23 [==============================] - 0s 1ms/step - loss: 0.4180 - accuracy: 0.8104\n",
            "Epoch 32/120\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4387 - accuracy: 0.8118\n",
            "Epoch 33/120\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4301 - accuracy: 0.8258\n",
            "Epoch 34/120\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4284 - accuracy: 0.8132\n",
            "Epoch 35/120\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4190 - accuracy: 0.8062\n",
            "Epoch 36/120\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4249 - accuracy: 0.8104\n",
            "Epoch 37/120\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4162 - accuracy: 0.8202\n",
            "Epoch 38/120\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4283 - accuracy: 0.8034\n",
            "Epoch 39/120\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4215 - accuracy: 0.8160\n",
            "Epoch 40/120\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4113 - accuracy: 0.8244\n",
            "Epoch 41/120\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4216 - accuracy: 0.8160\n",
            "Epoch 42/120\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4107 - accuracy: 0.8188\n",
            "Epoch 43/120\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4164 - accuracy: 0.8146\n",
            "Epoch 44/120\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4125 - accuracy: 0.8216\n",
            "Epoch 45/120\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4167 - accuracy: 0.8216\n",
            "Epoch 46/120\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4060 - accuracy: 0.8216\n",
            "Epoch 47/120\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4137 - accuracy: 0.8160\n",
            "Epoch 48/120\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4215 - accuracy: 0.8160\n",
            "Epoch 49/120\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4161 - accuracy: 0.8090\n",
            "Epoch 50/120\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4191 - accuracy: 0.8090\n",
            "Epoch 51/120\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4109 - accuracy: 0.8188\n",
            "Epoch 52/120\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4165 - accuracy: 0.8216\n",
            "Epoch 53/120\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4089 - accuracy: 0.8132\n",
            "Epoch 54/120\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4014 - accuracy: 0.8244\n",
            "Epoch 55/120\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4037 - accuracy: 0.8230\n",
            "Epoch 56/120\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4090 - accuracy: 0.8230\n",
            "Epoch 57/120\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4102 - accuracy: 0.8202\n",
            "Epoch 58/120\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4053 - accuracy: 0.8216\n",
            "Epoch 59/120\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4022 - accuracy: 0.8202\n",
            "Epoch 60/120\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4047 - accuracy: 0.8188\n",
            "Epoch 61/120\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.3950 - accuracy: 0.8287\n",
            "Epoch 62/120\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4046 - accuracy: 0.8216\n",
            "Epoch 63/120\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4104 - accuracy: 0.8272\n",
            "Epoch 64/120\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4173 - accuracy: 0.8216\n",
            "Epoch 65/120\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.3905 - accuracy: 0.8343\n",
            "Epoch 66/120\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.3981 - accuracy: 0.8329\n",
            "Epoch 67/120\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4082 - accuracy: 0.8216\n",
            "Epoch 68/120\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.3967 - accuracy: 0.8244\n",
            "Epoch 69/120\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4050 - accuracy: 0.8216\n",
            "Epoch 70/120\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.3947 - accuracy: 0.8230\n",
            "Epoch 71/120\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.3931 - accuracy: 0.8315\n",
            "Epoch 72/120\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.3981 - accuracy: 0.8301\n",
            "Epoch 73/120\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.4086 - accuracy: 0.8315\n",
            "Epoch 74/120\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.3965 - accuracy: 0.8315\n",
            "Epoch 75/120\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.3917 - accuracy: 0.8343\n",
            "Epoch 76/120\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.3963 - accuracy: 0.8216\n",
            "Epoch 77/120\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.3810 - accuracy: 0.8301\n",
            "Epoch 78/120\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.3839 - accuracy: 0.8385\n",
            "Epoch 79/120\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.3823 - accuracy: 0.8287\n",
            "Epoch 80/120\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.3912 - accuracy: 0.8343\n",
            "Epoch 81/120\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.3896 - accuracy: 0.8343\n",
            "Epoch 82/120\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.3894 - accuracy: 0.8371\n",
            "Epoch 83/120\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.3984 - accuracy: 0.8385\n",
            "Epoch 84/120\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.3970 - accuracy: 0.8132\n",
            "Epoch 85/120\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.3998 - accuracy: 0.8343\n",
            "Epoch 86/120\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.3958 - accuracy: 0.8258\n",
            "Epoch 87/120\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.3763 - accuracy: 0.8315\n",
            "Epoch 88/120\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.3947 - accuracy: 0.8315\n",
            "Epoch 89/120\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.3972 - accuracy: 0.8202\n",
            "Epoch 90/120\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.3819 - accuracy: 0.8343\n",
            "Epoch 91/120\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.3880 - accuracy: 0.8343\n",
            "Epoch 92/120\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.3926 - accuracy: 0.8385\n",
            "Epoch 93/120\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.3867 - accuracy: 0.8188\n",
            "Epoch 94/120\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.3885 - accuracy: 0.8399\n",
            "Epoch 95/120\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.3851 - accuracy: 0.8385\n",
            "Epoch 96/120\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.3916 - accuracy: 0.8272\n",
            "Epoch 97/120\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.3766 - accuracy: 0.8329\n",
            "Epoch 98/120\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.3791 - accuracy: 0.8371\n",
            "Epoch 99/120\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.3800 - accuracy: 0.8371\n",
            "Epoch 100/120\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.3826 - accuracy: 0.8329\n",
            "Epoch 101/120\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.3758 - accuracy: 0.8315\n",
            "Epoch 102/120\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.3887 - accuracy: 0.8329\n",
            "Epoch 103/120\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.3814 - accuracy: 0.8301\n",
            "Epoch 104/120\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.3924 - accuracy: 0.8230\n",
            "Epoch 105/120\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.3819 - accuracy: 0.8315\n",
            "Epoch 106/120\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.3903 - accuracy: 0.8287\n",
            "Epoch 107/120\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.3804 - accuracy: 0.8315\n",
            "Epoch 108/120\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.3884 - accuracy: 0.8315\n",
            "Epoch 109/120\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.3864 - accuracy: 0.8371\n",
            "Epoch 110/120\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.3809 - accuracy: 0.8315\n",
            "Epoch 111/120\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.3835 - accuracy: 0.8287\n",
            "Epoch 112/120\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.3688 - accuracy: 0.8399\n",
            "Epoch 113/120\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.3910 - accuracy: 0.8315\n",
            "Epoch 114/120\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.3825 - accuracy: 0.8301\n",
            "Epoch 115/120\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.3699 - accuracy: 0.8357\n",
            "Epoch 116/120\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.3797 - accuracy: 0.8357\n",
            "Epoch 117/120\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.3748 - accuracy: 0.8357\n",
            "Epoch 118/120\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.3853 - accuracy: 0.8357\n",
            "Epoch 119/120\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.3732 - accuracy: 0.8357\n",
            "Epoch 120/120\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.3752 - accuracy: 0.8357\n",
            "INFO:tensorflow:Assets written to: ./structured_data_classifier/best_model/assets\n",
            "WARNING:tensorflow:11 out of the last 11 calls to <function recreate_function.<locals>.restored_function_body at 0x7f797afee0d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:11 out of the last 11 calls to <function recreate_function.<locals>.restored_function_body at 0x7f797afeec80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:11 out of the last 11 calls to <function recreate_function.<locals>.restored_function_body at 0x7f79795230d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:11 out of the last 11 calls to <function recreate_function.<locals>.restored_function_body at 0x7f797b7352f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:11 out of the last 11 calls to <function recreate_function.<locals>.restored_function_body at 0x7f797b08cd08> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:11 out of the last 11 calls to <function recreate_function.<locals>.restored_function_body at 0x7f797a303488> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:11 out of the last 11 calls to <function recreate_function.<locals>.restored_function_body at 0x7f7976a77268> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "Métricas obtidas nos dados de teste:\n",
            "ROC Auc: 0.86\n",
            "Accuracy: 0.82\n",
            "F1 Score: 0.73\n",
            "Precision: 0.83\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hlV-lyN-XXVt"
      },
      "source": [
        "## 3.3 Comparação de resultados\n",
        "Na seguinte tabela podemos observar as diferentes métricas obtidas por ambos os modelos:\n",
        "\n",
        "| Modelo | ROC Auc | Accuracy | F1 Score | Precision\n",
        "|:---:|:---:|:---:|:---:|:---:|\n",
        "| Modelo `Keras` manual | 0.86 | 0.82 | **0.74** | 0.81 | \n",
        "| Modelo `AutoKeras` |  0.86 | 0.82 | 0.73 | **0.83** | \n",
        "\n",
        "Como é possível observar, ambos os modelos apresentaram resultados bastantes semelhantes, com diferenças minímas apenas no **F1 Score** e na **Precisão**.\n",
        "\n",
        "No também pode ser também interessante observar ambas as arquiteturas das duas redes criadas.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K4tU7hrjYPTC"
      },
      "source": [
        "\n",
        "**Estrutura Primeiro modelo:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CPLbDLS_YhGP",
        "outputId": "57d70466-d03d-47ec-d2f4-60ecbedc7aaa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Resumir primeiro modelo\n",
        "classic_model.summary()"
      ],
      "execution_count": 424,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_3 (Dense)              (None, 8)                 80        \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 8)                 72        \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 1)                 9         \n",
            "=================================================================\n",
            "Total params: 161\n",
            "Trainable params: 161\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZX1hgQ6_Ymi5"
      },
      "source": [
        "**Estrutura Modelo `AutoKeras`:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nKrnqJELYsgw",
        "outputId": "96f9d6ac-7e74-4790-aad8-19f83359d0a3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Resumir modelo `AutoKeras`\n",
        "auto_model.summary()"
      ],
      "execution_count": 426,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"functional_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         [(None, 9)]               0         \n",
            "_________________________________________________________________\n",
            "multi_category_encoding (Mul (None, 9)                 0         \n",
            "_________________________________________________________________\n",
            "normalization (Normalization (None, 9)                 19        \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 32)                320       \n",
            "_________________________________________________________________\n",
            "re_lu (ReLU)                 (None, 32)                0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 32)                1056      \n",
            "_________________________________________________________________\n",
            "re_lu_1 (ReLU)               (None, 32)                0         \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 32)                0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 1)                 33        \n",
            "_________________________________________________________________\n",
            "classification_head_1 (Activ (None, 1)                 0         \n",
            "=================================================================\n",
            "Total params: 1,428\n",
            "Trainable params: 1,409\n",
            "Non-trainable params: 19\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XJDa0MkWoeKf"
      },
      "source": [
        "**Diferenças encontradas:**\n",
        "\n",
        "Como podemos observar a rede neuronal construída pela biblioteca `AutoKeras` apresenta um nível de complexidade muito superior à rede neuronal construída manualmente. Enquanto a primeira rede apresenta 161 parâmetros treináveis, a segunda conta com quase nove vezes mais parâmetros treináveis (1409).\n",
        "\n",
        "Portanto no presente contexto não se justificaria a escolha da segunda rede neuronal, pois em regra geral, quando 2 ou mais modelos apresentam resultados bastante idênticos, deve-se adoptar o modelo mais simples. Isto leva a que:\n",
        "* O modelo seja mais facilmente explicável;\n",
        "* Menor tempo de treino, que por sua vez leva a menores custos de computação.\n",
        "\n",
        "A adoção de uma rede neuronal construída manualmente oferece ainda a vantagem de um maior controlo sobre todo o processo. No entanto é de notar que foram experimentados apenas `20` modelos diferentes pelo `AutoKeras`. Um aumento no número de experiências realizadas poderia traduzir-se na construção de um melhor modelo. O uso do `AutoKeras` é também uma ferramenta aconselhável a iniciantes de *machine learning*, pois abstrai o utilizador dos complicados conceitos matemáticos intrínsecos deste tópico.\n"
      ]
    }
  ]
}